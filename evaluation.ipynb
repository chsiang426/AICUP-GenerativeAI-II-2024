{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the training data split by ourselves\n",
    "test_img_dir = \"Training_dataset/test/imgs\"\n",
    "test_label_dir = \"Training_dataset/test/gts\"\n",
    "\n",
    "test_imgs = sorted([os.path.join(test_img_dir, f) for f in os.listdir(test_img_dir) if f.endswith(\".jpg\")])\n",
    "test_labels = sorted([os.path.join(test_label_dir, f) for f in os.listdir(test_label_dir) if f.endswith(\".png\")])\n",
    "\n",
    "test_imgs_length = len(test_imgs)\n",
    "test_labels_length = len(test_labels)\n",
    "print(\"test_imgs 長度:\", test_imgs_length)\n",
    "print(\"test_labels 長度:\", test_labels_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestlDataset(Dataset):  # Used for the testing set dataset\n",
    "    def __init__(self, images, img_size):\n",
    "        self.images = images\n",
    "        self.img_size = img_size\n",
    "        self.img_transform = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.images[index]).convert('RGB') # 打開圖像文件，轉換為RGB\n",
    "        image = self.img_transform(image)\n",
    "        name = os.path.basename(self.images[index]).replace('.jpg', '.png')\n",
    "        return image, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset = TestlDataset(images=test_imgs, img_size=256)\n",
    "ts_loader = DataLoader(dataset=ts_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.EncoderDecoderPatchGAN import VGG16Generator\n",
    "from models.UnetPatchGAN import UnetGenerator\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# 使用 best_model 資料夾內的模型權重\n",
    "model_Unet_465 = UnetGenerator().to(device)\n",
    "model_Unet_645 = UnetGenerator().to(device)\n",
    "model_Unet_680 = UnetGenerator().to(device)\n",
    "model_Unet_775 = UnetGenerator().to(device)\n",
    "model_EncoderDecoder_230 = VGG16Generator().to(device)\n",
    "\n",
    "model_Unet_465.load_state_dict(torch.load(\"best_models_weight/UNet_epoch_465.pth\"))\n",
    "model_Unet_645.load_state_dict(torch.load(\"best_models_weight/UNet_epoch_645.pth\"))\n",
    "model_Unet_680.load_state_dict(torch.load(\"best_models_weight/UNet_epoch_680.pth\"))\n",
    "model_Unet_775.load_state_dict(torch.load(\"best_models_weight/UNet_epoch_775.pth\"))\n",
    "model_EncoderDecoder_230.load_state_dict(torch.load(\"best_models_weight/EncoderDecoder_epoch_230.pth\"))\n",
    "\n",
    "model_Unet_465.eval()\n",
    "model_Unet_645.eval()\n",
    "model_Unet_680.eval()\n",
    "model_Unet_775.eval()\n",
    "model_EncoderDecoder_230.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_save_path = \"test_result\"\n",
    "os.makedirs(pred_save_path, exist_ok=True)\n",
    "\n",
    "# ensemble weights\n",
    "# 最終 private leaderboard 成績之各模型 ensemble weight 依序為：0.12 ,0.12, 0.33, 0.1, 0.33\n",
    "weight_Unet_465 = 0.12\n",
    "weight_Unet_645 = 0.12\n",
    "weight_Unet_680 = 0.33\n",
    "weight_Unet_775 = 0.1\n",
    "weight_EncoderDecoder_230 = 0.33 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, names in ts_loader:\n",
    "        images = images.cuda()\n",
    "        \n",
    "        result_Unet_465 = model_Unet_465(images) * weight_Unet_465\n",
    "        result_Unet_645 = model_Unet_645(images) * weight_Unet_645\n",
    "        result_Unet_680 = model_Unet_680(images) * weight_Unet_680\n",
    "        result_Unet_775 = model_Unet_775(images) * weight_Unet_775\n",
    "        result_EncoderDecoder_230 = model_EncoderDecoder_230(images) * weight_EncoderDecoder_230\n",
    "\n",
    "        results =  result_Unet_465 + result_Unet_645 + result_Unet_680 + result_Unet_775 + result_EncoderDecoder_230\n",
    "\n",
    "        results = F.interpolate(results, size=(240, 428), mode='bicubic', align_corners=True)  \n",
    "        results = results.data.cpu().numpy()\n",
    "        for idx, name in enumerate(names):\n",
    "            res = results[idx].squeeze()\n",
    "            success = cv2.imwrite(os.path.join(pred_save_path, name), res * 255)\n",
    "            if success:\n",
    "                print(f\"File saved successfully: {name}\")\n",
    "            else:\n",
    "                print(f\"Failed to save file: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate mean F-measure score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lartpang/PySODMetrics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_sod_metrics\n",
    "\n",
    "# define mean F-measure function\n",
    "def calculate_mean_F_measure(pred_save_path, test_labels, opening=False):\n",
    "    FMv2 = py_sod_metrics.FmeasureV2(\n",
    "        metric_handlers={\n",
    "            \"fm\": py_sod_metrics.FmeasureHandler(with_dynamic=True, with_adaptive=False, beta=0.3),\n",
    "        }\n",
    "    )\n",
    "    if opening:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "        file_names = os.listdir(pred_save_path)\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(pred_save_path, file_name)\n",
    "            if file_path.lower().endswith(('.png')):\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "                cv2.imwrite(file_path, image)\n",
    "\n",
    "    for i, mask_name in enumerate(test_labels):                    \n",
    "        mask_path = mask_name\n",
    "        pred_path = os.path.join(pred_save_path, os.path.basename(mask_name))\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        pred = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "        FMv2.step(pred=pred, gt=mask)\n",
    "    fmv2 = FMv2.get_results()\n",
    "    results = {\n",
    "        \"meanfm\": fmv2[\"fm\"][\"dynamic\"].mean()\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算 Mean F-measure\n",
    "# before binarizing\n",
    "print(\"before binarizing\")\n",
    "print(calculate_mean_F_measure(pred_save_path=pred_save_path, test_labels=test_labels))\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# do binarize\n",
    "file_names = os.listdir(pred_save_path)\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(pred_save_path, file_name)\n",
    "    if file_path.lower().endswith(('.png')):\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        cv2.imwrite(file_path, binary_image)\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# after binarizing\n",
    "print(\"after binarizing\")\n",
    "print(calculate_mean_F_measure(pred_save_path=pred_save_path, test_labels=test_labels))\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# opening and after binarizing\n",
    "print(\"after binarizing and opening\")\n",
    "print(calculate_mean_F_measure(pred_save_path=pred_save_path, test_labels=test_labels, opening=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_img_dir = \"Public_testing_dataset/img\"\n",
    "private_img_dir = \"Private_testing_dataset/img\"\n",
    "public_imgs = sorted([os.path.join(public_img_dir, f) for f in os.listdir(public_img_dir) if f.endswith(\".jpg\")])\n",
    "private_imgs = sorted([os.path.join(private_img_dir, f) for f in os.listdir(private_img_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "public_ts_dataset = TestlDataset(images=public_imgs, img_size=256)\n",
    "public_ts_loader = DataLoader(dataset=public_ts_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
    "private_ts_dataset = TestlDataset(images=private_imgs, img_size=256)\n",
    "private_ts_loader = DataLoader(dataset=private_ts_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate public and private datasets\n",
    "submission_save_path = \"submission/\"\n",
    "os.makedirs(submission_save_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # public dataset\n",
    "    for images, names in public_ts_loader:\n",
    "        images = images.cuda()\n",
    "\n",
    "        result_Unet_465 = model_Unet_465(images) * weight_Unet_465\n",
    "        result_Unet_645 = model_Unet_645(images) * weight_Unet_645\n",
    "        result_Unet_680 = model_Unet_680(images) * weight_Unet_680\n",
    "        result_Unet_775 = model_Unet_775(images) * weight_Unet_775\n",
    "        result_EncoderDecoder_230 = model_EncoderDecoder_230(images) * weight_EncoderDecoder_230\n",
    "\n",
    "        results =  result_Unet_465 + result_Unet_645 + result_Unet_680 + result_Unet_775 + result_EncoderDecoder_230\n",
    "\n",
    "        results = F.interpolate(results, size=(240, 428), mode='bicubic', align_corners=True)\n",
    "\n",
    "        results = results.data.cpu().numpy()\n",
    "        for idx, name in enumerate(names):\n",
    "            res = results[idx].squeeze()\n",
    "            success = cv2.imwrite(os.path.join(submission_save_path, name), res * 255)\n",
    "            if success:\n",
    "                print(f\"File saved successfully: {name}\")\n",
    "            else:\n",
    "                print(f\"Failed to save file: {name}\")\n",
    "    \n",
    "    # private dataset\n",
    "    for images, names in private_ts_loader:\n",
    "        images = images.cuda()\n",
    "\n",
    "        result_Unet_465 = model_Unet_465(images) * weight_Unet_465\n",
    "        result_Unet_645 = model_Unet_645(images) * weight_Unet_645\n",
    "        result_Unet_680 = model_Unet_680(images) * weight_Unet_680\n",
    "        result_Unet_775 = model_Unet_775(images) * weight_Unet_775\n",
    "        result_EncoderDecoder_230 = model_EncoderDecoder_230(images) * weight_EncoderDecoder_230\n",
    "\n",
    "        results =  result_Unet_465 + result_Unet_645 + result_Unet_680 + result_Unet_775 + result_EncoderDecoder_230\n",
    "\n",
    "        results = F.interpolate(results, size=(240, 428), mode='bicubic', align_corners=True)\n",
    "\n",
    "        results = results.data.cpu().numpy()\n",
    "        for idx, name in enumerate(names):\n",
    "            res = results[idx].squeeze()\n",
    "            success = cv2.imwrite(os.path.join(submission_save_path, name), res * 255)\n",
    "            if success:\n",
    "                print(f\"File saved successfully: {name}\")\n",
    "            else:\n",
    "                print(f\"Failed to save file: {name}\")\n",
    "\n",
    "\n",
    "# binarizing and opening\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "file_names = os.listdir(submission_save_path)\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(submission_save_path, file_name)\n",
    "    if file_path.lower().endswith(('.png')):\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        cv2.imwrite(file_path, binary_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 壓縮檔案成 zip 檔\n",
    "shutil.make_archive('submission_file', 'zip', submission_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
